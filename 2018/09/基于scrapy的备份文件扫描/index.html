<!DOCTYPE html>
<html lang="zh-CN">










<head>
    <meta charset="utf-8" />
    <link rel="apple-touch-icon" sizes="76x76" href="/favicon.ico">
    <link rel="icon" type="image/png" href="/favicon.ico">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0, shrink-to-fit=no" name="viewport" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="description" content="One way to choose one">
    <meta name="author" content="Misaki">
    <meta name="keywords" content="">
    <title>基于scrapy的备份文件扫描 ~ Misaki&#39;s Blog</title>
    
<link rel="stylesheet" href="/css/Material_Icons.css">

    <!-- 
<link rel="stylesheet" href="/css/font-awesome.css">
 -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css">
    
<link rel="stylesheet" href="/css/main.css">

    
        
<link rel="stylesheet" href="/css/post.css">

        
            
<link rel="stylesheet" href="/css/Prettify/tomorrow-night-eighties.min.css">

        
    
<meta name="generator" content="Hexo 5.2.0"></head>

<body class=" sidebar-collapse">
<nav class="navbar navbar-transparent navbar-color-on-scroll fixed-top navbar-expand-lg" color-on-scroll="100" id="sectionsNav">
    <div class="container">
        <div class="navbar-translate">
            <a class="navbar-brand" href="/">
                Misaki&#39;s Blog</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" aria-expanded="false" aria-label="Toggle navigation">
                <span class="sr-only">Toggle navigation</span>
                <span class="navbar-toggler-icon"></span>
                <span class="navbar-toggler-icon"></span>
                <span class="navbar-toggler-icon"></span>
            </button>
        </div>
            <div class="collapse navbar-collapse">
                <ul class="navbar-nav ml-auto">
                    
                        
                            <li class="nav-item">
                                <a class="nav-link" href="/archives/">
                                    archives
                                </a>
                            </li>
                        
                            <li class="nav-item">
                                <a class="nav-link" href="/about/">
                                    about
                                </a>
                            </li>
                        
                    
                    
                        
                            <li class="nav-item">
                                <a class="nav-link" rel="tooltip" title="" data-placement="bottom" href="https://github.com/MisakiKata" target="_blank" data-original-title="See me here">
                                    <i class="fa fa-github"></i>
                                </a>
                            </li>
                        
                            <li class="nav-item">
                                <a class="nav-link" rel="tooltip" title="" data-placement="bottom" href="https://www.t00ls.net/members-profile-12179.html" target="_blank" data-original-title="See me here">
                                    <i class="fa fa-twitch"></i>
                                </a>
                            </li>
                        
                            <li class="nav-item">
                                <a class="nav-link" rel="tooltip" title="" data-placement="bottom" href="https://misakikata.github.io/atom.xml" target="_blank" data-original-title="See me here">
                                    <i class="fa fa-rss"></i>
                                </a>
                            </li>
                        
                            <li class="nav-item">
                                <a class="nav-link" rel="tooltip" title="" data-placement="bottom" href="mailto:misakikatas@gmail.com" target="_blank" data-original-title="See me here">
                                    <i class="fa fa-envelope"></i>
                                </a>
                            </li>
                        
                    
                </ul>
            </div>
    </div>
</nav>
    
  <div class="page-header header-filter" data-parallax="true" style="background-image: url('/img/post-banner.jpg'); height: 70vh;">
    
      <div class="container">
        <h1 class="title text-center post_title">基于scrapy的备份文件扫描</h1>
        <p class="text-center"><b>Thursday, September 27th 2018, 10:51 am</b></p>
      </div>
    
  </div>

  
  
  
    <div class="row" style="margin: 0 0 0; z-index: 999;">
  <div class="col-md-8 offset-md-1">
    <div class="main main-raised">
      <div class="container">
        <div class="section">
          <div class="post_content">
              <p>Scrapy，Python开发的一个快速、高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动测试。</p>
<p>首先生成项目文件</p>
<pre class="line-numbers language-none"><code class="language-none">scrapy startproject spiderdata<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>生成成功后，会有以下目录结构，首先在spiderdata中的spider目录创建我们的spider文件。</p>
<p><img src="%5C2018%5C09%5C%E5%9F%BA%E4%BA%8Escrapy%E7%9A%84%E5%A4%87%E4%BB%BD%E6%96%87%E4%BB%B6%E6%89%AB%E6%8F%8F%5C1538017021874.png" alt="1538017021874"></p>
<p>备份文件扫描文件名，有两个选择，一是基于字典，二是根据url的备份文件名，从以往发现备份文件的结果上看，两种方式都是经常存在使用的。</p>
<p>于是创建backup文件，用来生成备份文件名，创建一个列表用来存储字典文件名，另外创建一个方法用来基于url生成备份文件名。</p>
<pre class="line-numbers language-none"><code class="language-none">#coding:utf-8

import urlparse

class backup(object):
    def __init__(self, url):
        self.url &#x3D; url
        self.list2 &#x3D; [&#39;&#x2F;db.zip&#39;, &#39;&#x2F;fdsa.rar&#39;, &#39;&#x2F;ftp.rar&#39;, &#39;&#x2F;gg.rar&#39;, &#39;&#x2F;hdocs.rar&#39;, &#39;&#x2F;hdocs.zip&#39;, &#39;&#x2F;a.zip&#39;, &#39;&#x2F;web.zip&#39;,
                      &#39;&#x2F;web.rar&#39;, &#39;&#x2F;1.rar&#39;, &#39;&#x2F;bbs.rar&#39;, &#39;&#x2F;www.root.rar&#39;,
                      &#39;&#x2F;123.rar&#39;, &#39;&#x2F;data.rar&#39;, &#39;&#x2F;bak.rar&#39;, &#39;&#x2F;oa.rar&#39;, &#39;&#x2F;admin.rar&#39;, &#39;&#x2F;www.rar&#39;, &#39;&#x2F;2014.rar&#39;,
                      &#39;&#x2F;2015.rar&#39;, &#39;&#x2F;2016.rar&#39;, &#39;&#x2F;2014.zip&#39;, &#39;&#x2F;2015.zip&#39;, &#39;&#x2F;2016.zip&#39;,
                      &#39;&#x2F;2017.zip&#39;, &#39;&#x2F;1.zip&#39;, &#39;&#x2F;1.gz&#39;, &#39;&#x2F;1.tar.gz&#39;, &#39;&#x2F;2.zip&#39;, &#39;&#x2F;2.rar&#39;, &#39;&#x2F;123.rar&#39;, &#39;&#x2F;123.zip&#39;, &#39;&#x2F;a.rar&#39;,
                      &#39;&#x2F;a.zip&#39;, &#39;&#x2F;admin.rar&#39;, &#39;&#x2F;back.rar&#39;, &#39;&#x2F;backup.rar&#39;, &#39;&#x2F;bak.rar&#39;,
                      &#39;&#x2F;bbs.rar&#39;, &#39;&#x2F;bbs.zip&#39;, &#39;&#x2F;beifen.rar&#39;, &#39;&#x2F;beifen.zip&#39;, &#39;&#x2F;beian.rar&#39;, &#39;&#x2F;data.rar&#39;, &#39;&#x2F;data.zip&#39;,
                      &#39;&#x2F;HYTop.rar&#39;, &#39;&#x2F;root.rar&#39;, &#39;&#x2F;Release.rar&#39;, &#39;&#x2F;Release.zip&#39;, &#39;&#x2F;sql.rar&#39;,
                      &#39;&#x2F;test.rar&#39;, &#39;&#x2F;template.rar&#39;, &#39;&#x2F;template.zip&#39;, &#39;&#x2F;upfile.rar&#39;, &#39;&#x2F;vip.rar&#39;, &#39;&#x2F;wangzhan.rar&#39;,
                      &#39;&#x2F;wangzhan.zip&#39;, &#39;&#x2F;web.rar&#39;, &#39;&#x2F;web.zip&#39;, &#39;&#x2F;website.rar&#39;, &#39;&#x2F;www.rar&#39;,
                      &#39;&#x2F;www.zip&#39;, &#39;&#x2F;wwwroot.rar&#39;, &#39;&#x2F;wwwroot.zip&#39;, &#39;&#x2F;wz.rar&#39;]

    def backup(self):
        list_a &#x3D; []
        parse &#x3D; urlparse.urlparse(self.url)
        name &#x3D; parse.netloc.split(&#39;.&#39;)
        name_url &#x3D; parse.netloc.replace(&#39;.&#39;, &#39;&#39;)
        for i in [&#39;.rar&#39;, &#39;.zip&#39;, &#39;.tar.gz&#39;, &#39;.7z&#39;]:
            list_a.append(parse.scheme + &#39;:&#x2F;&#x2F;&#39; + parse.netloc + &#39;&#x2F;&#39; + parse.netloc + i)   #http:&#x2F;&#x2F;www.baidu.com&#x2F;www.baidu.com.zip
            if &#39;www&#39; in name:
                list_a.append(self.url + &#39;&#x2F;&#39; + name[1] + i)   #http:&#x2F;&#x2F;www.baidu.com&#x2F;baidu.zip
                list_a.append(self.url + &#39;&#x2F;&#39; + &#39;&#39;.join(name[1:]) + i)     #http:&#x2F;&#x2F;www.baidu.com&#x2F;baiducom.zip
            else:
                list_a.append(self.url + &#39;&#x2F;&#39; + name[0] + i)       #http:&#x2F;&#x2F;www.baidu.com&#x2F;baidu.zip
            list_a.append(self.url + &#39;&#x2F;&#39; + name_url + i)     #http:&#x2F;&#x2F;www.baidu.com&#x2F;wwwbaiducom.zip
        for x in self.list2:
            list_a.append(self.url + x)
        return list_a<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>在spider的爬虫文件中使用以下代码</p>
<pre class="line-numbers language-none"><code class="language-none">#coding:utf-8

import scrapy
from backup import backup
from ..items import SpiderdateItem

class spiderdata(scrapy.Spider):

    name &#x3D; &quot;spiderdata&quot;
    content_type &#x3D; [&#39;application&#x2F;x-rar&#39;,&#39;application&#x2F;x-gzip&#39;,&#39;application&#x2F;zip&#39;,&#39;application&#x2F;octet-stream&#39;,&#39;application&#x2F;x-7z-compressed&#39;]

    def start_requests(self):
        with open(&#39;ip.txt&#39;,&#39;r&#39;) as f:
            for i in f.readlines():
                ip &#x3D; i.strip(&#39;\n&#39;)
                back &#x3D; backup(ip)
                url_ip &#x3D; back.backup()
                for x in url_ip:
                    yield scrapy.Request(x, callback&#x3D;self.parse,dont_filter&#x3D;True)

    def parse(self, response):
        item &#x3D; SpiderdateItem()
        if response.headers[&#39;Content-Type&#39;] in self.content_type:
            print &quot;[&quot; + str(response.status) + &quot;]&quot; + u&#39; 检测到存在备份文件的URL: &#39;+ response.url
            item[&#39;url&#39;] &#x3D; response.url
            yield item<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>调用之前创建的备份文件名函数，使用start_requests来生成一个可迭代对象。</p>
<p>数据通过item来保存本地，所以在items中创建一个参数，并且在settings中开启item管道。</p>
<pre class="line-numbers language-none"><code class="language-none">url &#x3D; scrapy.Field()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>在piplines中创建本地文件保存文件，创建一次文件对象，写入后根据 爬虫关闭后再关闭本地文件。</p>
<pre class="line-numbers language-none"><code class="language-none">def __init__(self):
    self.f &#x3D; open(&quot;url.txt&quot;,&#39;w&#39;)

def process_item(self, item, spider):
    self.f.write(item[&#39;url&#39;].encode(&quot;utf-8&quot;)+&#39;\n&#39;)
    return item

def close_spider(self, spider):
    self.f.close()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>因此只需在spiderdata中创建ip.txt文件即可，写入需要检测的url，另外如果不想看到scrapy的log输出，可以用在setting中添加如下：</p>
<pre class="line-numbers language-none"><code class="language-none">LOG_LEVEL &#x3D; &#39;WARNING&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>只显示warning级的log输出.</p>

          </div>
          <br><br>
              
                <div class="license-wrapper">
                    <p>原文作者：<a href="https://misakikata.github.io">Misaki</a>
                    <p>原文链接：<a href="https://misakikata.github.io/2018/09/%E5%9F%BA%E4%BA%8Escrapy%E7%9A%84%E5%A4%87%E4%BB%BD%E6%96%87%E4%BB%B6%E6%89%AB%E6%8F%8F/">https://misakikata.github.io/2018/09/%E5%9F%BA%E4%BA%8Escrapy%E7%9A%84%E5%A4%87%E4%BB%BD%E6%96%87%E4%BB%B6%E6%89%AB%E6%8F%8F/</a>
                    <p>发表日期：<a href="https://misakikata.github.io/2018/09/%E5%9F%BA%E4%BA%8Escrapy%E7%9A%84%E5%A4%87%E4%BB%BD%E6%96%87%E4%BB%B6%E6%89%AB%E6%8F%8F/">September 27th 2018, 10:51:38 am</a>
                    <p>更新日期：<a href="https://misakikata.github.io/2018/09/%E5%9F%BA%E4%BA%8Escrapy%E7%9A%84%E5%A4%87%E4%BB%BD%E6%96%87%E4%BB%B6%E6%89%AB%E6%8F%8F/">September 27th 2018, 11:12:06 am</a>
                    <p>版权声明：本文采用<a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc/4.0/">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可</p>
                </div>
              
          <br><br>
          <div>
              <p>
                       
                      <span class="badge badge-default">#&nbsp;python</span>
                      &nbsp;
                      
              </p>
          </div>
        </div>
      </div>  
    </div>
  </div>
  <!-- TOC -->
  
      <div class="">
        <div id="toc">
          <p class="toc-title"><i class="material-icons" style="vertical-align:middle">toc</i>Toc:</p> 
          <div id="tocbot"></div>
        </div>
      </div>
  
</div>


<!-- Comments -->
<div class="row">
    <div class="col-md-8 offset-md-2">
    
        
            <div class="disqus" style="width:100%">
    <div id="disqus_thread"></div>
    <script>               
        var disqus_shortname = '';
        var disqus_config = function () {
            this.page.url = 'https://misakikata.github.io/2018/09/基于scrapy的备份文件扫描/'; 
            this.page.identifier = '/2018/09/基于scrapy的备份文件扫描/';
        };
        (function() { 
            var d = document, s = d.createElement('script');
            s.type = 'text/javascript';
            s.src = '//'+disqus_shortname+'.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>                                
</div>
        
    
    </div>
</div>
  

<footer class="footer footer-default">
        <div class="container">
          <div class="float-left" style="padding: 15px 0;">
              <b>假如今天的你被生活辜负了，别伤心，因为明天生活还会继续辜负你！</b>
          </div>
          <div align="right" style="padding: 15px 0;">
              <i class="iconfont icon-love" ></i>
              <a href="https://github.com/0x2e/Material-T" target="_blank"> <b>Material-T</b></a>
          </div>
        </div>
</footer>
      <!--   Core JS Files   -->
      
<script src="/js/core/jquery.min.js?v=3.2.1.js"></script>

      
<script src="/js/main.js"></script>

      
<script src="/js/core/popper.min.js"></script>

      
<script src="/js/core/bootstrap-material-design.min.js"></script>

      
<script src="/js/plugins/moment.min.js"></script>

      
<script src="/js/material-kit.min.js?v=2.0.5.js"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js"></script>
        
<script src="/js/post.js"></script>

        
<script src="/js/plugins/prettify.js"></script>

        <script>
            $(document).ready(function(){
                $('pre').addClass('prettyprint linenums');
                prettyPrint();
            })
        </script>
      
<script src="/live2d-widget/autoload.js"></script>
</body>
</html>